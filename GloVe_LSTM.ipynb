{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3acbe59-a26a-4261-8d3f-0bb80c974029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "import gensim.downloader as api\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b21929e1-bf9a-4388-8f48-a0754ffb298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_lg\n",
    "glove_model = spacy.load('en_core_web_lg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "682cbd40-5f4d-49e4-aa88-236096df8bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_data.csv', index_col=0)\n",
    "test_data = pd.read_csv('data/test_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "376f76a4-41be-42e3-aac9-f02919ab733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len = 256\n",
    "max_title_len = 32\n",
    "\n",
    "# Truncate the token lists\n",
    "train_data['text_tokens'] = train_data['text_tokens'].apply(lambda x: x[:max_text_len])\n",
    "train_data['title_tokens'] = train_data['title_tokens'].apply(lambda x: x[:max_title_len])\n",
    "\n",
    "test_data['text_tokens'] = test_data['text_tokens'].apply(lambda x: x[:max_text_len])\n",
    "test_data['title_tokens'] = test_data['title_tokens'].apply(lambda x: x[:max_title_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66965ef7-22cc-41c3-b509-92187919a9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9826ba4b-6818-457f-a03a-92139dbc723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_tokens(df, title_max_len=32, text_max_len=256):\n",
    "    title_vectors = []\n",
    "    text_vectors = []\n",
    "    labels = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # --- Title ---\n",
    "        title_vec = []\n",
    "        for token in row['title_tokens'][:title_max_len]:\n",
    "            if token in glove_model.vocab and glove_model.vocab[token].has_vector:\n",
    "                title_vec.append(glove_model.vocab[token].vector)\n",
    "            else:\n",
    "                title_vec.append(np.zeros(embedding_dim, dtype=np.float32))\n",
    "        while len(title_vec) < title_max_len:\n",
    "            title_vec.append(np.zeros(embedding_dim, dtype=np.float32))\n",
    "        title_vectors.append(title_vec)\n",
    "\n",
    "        # --- Text ---\n",
    "        text_vec = []\n",
    "        for token in row['text_tokens'][:text_max_len]:\n",
    "            if token in glove_model.vocab and glove_model.vocab[token].has_vector:\n",
    "                text_vec.append(glove_model.vocab[token].vector)\n",
    "            else:\n",
    "                text_vec.append(np.zeros(embedding_dim, dtype=np.float32))\n",
    "        while len(text_vec) < text_max_len:\n",
    "            text_vec.append(np.zeros(embedding_dim, dtype=np.float32))\n",
    "        text_vectors.append(text_vec)\n",
    "\n",
    "        labels.append(row['label'])\n",
    "\n",
    "    return (\n",
    "        np.array(title_vectors, dtype=np.float32),\n",
    "        np.array(text_vectors, dtype=np.float32),\n",
    "        np.array(labels, dtype=np.int64)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "158be174-c41f-48b7-b37c-957e985c6e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_title_vecs, train_text_vecs, train_labels = embed_tokens(train_data)\n",
    "test_title_vecs, test_text_vecs, test_labels = embed_tokens(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fd952ec-a58c-4ae3-8eb8-d3c42460a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_dataset(Dataset):\n",
    "    def __init__(self, title_vecs, text_vecs, labels):\n",
    "        self.title_vecs = torch.tensor(title_vecs, dtype=torch.float32)\n",
    "        self.text_vecs = torch.tensor(text_vecs, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.title_vecs[idx], self.text_vecs[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "614d88fd-da35-4cea-813e-263e89d64fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = my_dataset(train_title_vecs, train_text_vecs, train_labels)\n",
    "test_dataset = my_dataset(test_title_vecs, test_text_vecs, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc868c4d-4c38-40bf-9e92-7279a5aab7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c8ccf55-161f-41d3-a963-649b37b1e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DualLSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim=300, hidden_dim=128, num_classes=2):\n",
    "        super(DualLSTMClassifier, self).__init__()\n",
    "        self.title_lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.text_lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, title_input, text_input):\n",
    "\n",
    "        _, (title_hidden, _) = self.title_lstm(title_input)\n",
    "        _, (text_hidden, _) = self.text_lstm(text_input)\n",
    "\n",
    "        title_hidden = title_hidden[-1]\n",
    "        text_hidden = text_hidden[-1]\n",
    "\n",
    "        combined = torch.cat((title_hidden, text_hidden), dim=1) \n",
    "        combined = self.dropout(combined)\n",
    "        output = self.fc(combined)  \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97fbe0ed-26b2-49bc-bfa2-8e8658356245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "282629e7-abf4-45ab-bb48-39d340da0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DualLSTMClassifier()\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "975f9cf2-ef87-44c4-af3f-e26676454c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Loss: 1039.3350 | Accuracy: 0.5827\n",
      "Epoch 2/20 | Loss: 968.9186 | Accuracy: 0.6441\n",
      "Epoch 3/20 | Loss: 851.6899 | Accuracy: 0.7108\n",
      "Epoch 4/20 | Loss: 817.5990 | Accuracy: 0.7223\n",
      "Epoch 5/20 | Loss: 775.4721 | Accuracy: 0.7430\n",
      "Epoch 6/20 | Loss: 746.9771 | Accuracy: 0.7582\n",
      "Epoch 7/20 | Loss: 698.1593 | Accuracy: 0.7807\n",
      "Epoch 8/20 | Loss: 668.3558 | Accuracy: 0.7925\n",
      "Epoch 9/20 | Loss: 647.8849 | Accuracy: 0.8000\n",
      "Epoch 10/20 | Loss: 622.1323 | Accuracy: 0.8113\n",
      "Epoch 11/20 | Loss: 600.1943 | Accuracy: 0.8178\n",
      "Epoch 12/20 | Loss: 636.3847 | Accuracy: 0.8057\n",
      "Epoch 13/20 | Loss: 555.6847 | Accuracy: 0.8335\n",
      "Epoch 14/20 | Loss: 436.3181 | Accuracy: 0.8683\n",
      "Epoch 15/20 | Loss: 413.3083 | Accuracy: 0.8777\n",
      "Epoch 16/20 | Loss: 393.6644 | Accuracy: 0.8858\n",
      "Epoch 17/20 | Loss: 359.5535 | Accuracy: 0.8958\n",
      "Epoch 18/20 | Loss: 331.4814 | Accuracy: 0.9071\n",
      "Epoch 19/20 | Loss: 305.7290 | Accuracy: 0.9145\n",
      "Epoch 20/20 | Loss: 289.0188 | Accuracy: 0.9216\n"
     ]
    }
   ],
   "source": [
    "num_epochs =20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for title_batch, text_batch, labels in train_loader:\n",
    "        title_batch = title_batch.to(device)\n",
    "        text_batch = text_batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(title_batch, text_batch)  \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Accuracy\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} | Loss: {epoch_loss:.4f} | Accuracy: {acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b201232-41ed-4522-9f5e-7265d80ffceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for title_batch, text_batch, _ in test_loader:\n",
    "        title_batch = title_batch.to(device)\n",
    "        text_batch = text_batch.to(device)\n",
    "\n",
    "        outputs = model(title_batch, text_batch)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ebc37ba-2831-42e7-9d4b-9ddac64054b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({\n",
    "    'label': test_labels,\n",
    "    'pred_glove': all_preds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4eb15c0d-ea69-46a6-8c6c-42f1f6888984",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('test_with_glove.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48766eb1-ec98-4506-b6fd-0d6adad2adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/lstm_glove.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada26e4c-9a78-4bb9-ab4f-19070f3e6c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
