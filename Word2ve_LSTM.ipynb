{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3acbe59-a26a-4261-8d3f-0bb80c974029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "import gensim.downloader as api\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26afa21d-c1fc-4045-89bf-08ff0975e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = api.load(\"word2vec-google-news-300\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "682cbd40-5f4d-49e4-aa88-236096df8bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_data.csv', index_col=0)\n",
    "test_data = pd.read_csv('data/test_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "376f76a4-41be-42e3-aac9-f02919ab733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len = 256\n",
    "max_title_len = 32\n",
    "\n",
    "# Truncate the token lists\n",
    "train_data['text_tokens'] = train_data['text_tokens'].apply(lambda x: x[:max_text_len])\n",
    "train_data['title_tokens'] = train_data['title_tokens'].apply(lambda x: x[:max_title_len])\n",
    "\n",
    "test_data['text_tokens'] = test_data['text_tokens'].apply(lambda x: x[:max_text_len])\n",
    "test_data['title_tokens'] = test_data['title_tokens'].apply(lambda x: x[:max_title_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66965ef7-22cc-41c3-b509-92187919a9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = w2v_model.vector_size  \n",
    "embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9826ba4b-6818-457f-a03a-92139dbc723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_tokens(df,title_max_len=32, text_max_len=256):\n",
    "    title_vectors = []\n",
    "    text_vectors = []\n",
    "    labels = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        title_vec = []\n",
    "        for token in row['title_tokens'][:title_max_len]:\n",
    "            if token in w2v_model:\n",
    "                title_vec.append(w2v_model[token])\n",
    "            else:\n",
    "                title_vec.append(np.zeros(embedding_dim, dtype=np.float32))\n",
    "        while len(title_vec) < title_max_len:\n",
    "            title_vec.append(np.zeros(embedding_dim, dtype=np.float32))\n",
    "        title_vectors.append(title_vec)\n",
    "\n",
    "        text_vec = []\n",
    "        for token in row['text_tokens'][:text_max_len]:\n",
    "            if token in w2v_model:\n",
    "                text_vec.append(w2v_model[token])\n",
    "            else:\n",
    "                text_vec.append(np.zeros(embedding_dim, dtype=np.float32))\n",
    "        while len(text_vec) < text_max_len:\n",
    "            text_vec.append(np.zeros(embedding_dim, dtype=np.float32))\n",
    "        text_vectors.append(text_vec)\n",
    "\n",
    "        # --- Label ---\n",
    "        labels.append(row['label'])\n",
    "\n",
    "    return (\n",
    "        np.array(title_vectors, dtype=np.float32),\n",
    "        np.array(text_vectors, dtype=np.float32),\n",
    "        np.array(labels, dtype=np.int64)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "158be174-c41f-48b7-b37c-957e985c6e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_title_vecs, train_text_vecs, train_labels = embed_tokens(train_data)\n",
    "test_title_vecs, test_text_vecs, test_labels = embed_tokens(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fd952ec-a58c-4ae3-8eb8-d3c42460a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_dataset(Dataset):\n",
    "    def __init__(self, title_vecs, text_vecs, labels):\n",
    "        self.title_vecs = torch.tensor(title_vecs, dtype=torch.float32)\n",
    "        self.text_vecs = torch.tensor(text_vecs, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.title_vecs[idx], self.text_vecs[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "614d88fd-da35-4cea-813e-263e89d64fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = my_dataset(train_title_vecs, train_text_vecs, train_labels)\n",
    "test_dataset = my_dataset(test_title_vecs, test_text_vecs, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc868c4d-4c38-40bf-9e92-7279a5aab7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c8ccf55-161f-41d3-a963-649b37b1e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DualLSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim=300, hidden_dim=128, num_classes=2):\n",
    "        super(DualLSTMClassifier, self).__init__()\n",
    "        self.title_lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.text_lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, title_input, text_input):\n",
    "\n",
    "        _, (title_hidden, _) = self.title_lstm(title_input)\n",
    "        _, (text_hidden, _) = self.text_lstm(text_input)\n",
    "\n",
    "        title_hidden = title_hidden[-1]\n",
    "        text_hidden = text_hidden[-1]\n",
    "\n",
    "        combined = torch.cat((title_hidden, text_hidden), dim=1) \n",
    "        combined = self.dropout(combined)\n",
    "        output = self.fc(combined)  \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97fbe0ed-26b2-49bc-bfa2-8e8658356245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "282629e7-abf4-45ab-bb48-39d340da0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DualLSTMClassifier()\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "975f9cf2-ef87-44c4-af3f-e26676454c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 | Loss: 1049.8041 | Accuracy: 0.5701\n",
      "Epoch 2/25 | Loss: 1029.5378 | Accuracy: 0.5934\n",
      "Epoch 3/25 | Loss: 1020.6975 | Accuracy: 0.5999\n",
      "Epoch 4/25 | Loss: 992.2839 | Accuracy: 0.6135\n",
      "Epoch 5/25 | Loss: 944.5045 | Accuracy: 0.6512\n",
      "Epoch 6/25 | Loss: 884.6549 | Accuracy: 0.6860\n",
      "Epoch 7/25 | Loss: 843.0553 | Accuracy: 0.7088\n",
      "Epoch 8/25 | Loss: 810.0390 | Accuracy: 0.7267\n",
      "Epoch 9/25 | Loss: 784.3625 | Accuracy: 0.7408\n",
      "Epoch 10/25 | Loss: 763.1504 | Accuracy: 0.7523\n",
      "Epoch 11/25 | Loss: 736.0814 | Accuracy: 0.7649\n",
      "Epoch 12/25 | Loss: 713.5872 | Accuracy: 0.7724\n",
      "Epoch 13/25 | Loss: 694.5362 | Accuracy: 0.7789\n",
      "Epoch 14/25 | Loss: 669.9274 | Accuracy: 0.7917\n",
      "Epoch 15/25 | Loss: 657.3259 | Accuracy: 0.7955\n",
      "Epoch 16/25 | Loss: 636.5948 | Accuracy: 0.8046\n",
      "Epoch 17/25 | Loss: 616.4923 | Accuracy: 0.8120\n",
      "Epoch 18/25 | Loss: 462.8455 | Accuracy: 0.8615\n",
      "Epoch 19/25 | Loss: 393.5492 | Accuracy: 0.8860\n",
      "Epoch 20/25 | Loss: 361.8332 | Accuracy: 0.8956\n",
      "Epoch 21/25 | Loss: 331.5704 | Accuracy: 0.9068\n",
      "Epoch 22/25 | Loss: 298.7132 | Accuracy: 0.9173\n",
      "Epoch 23/25 | Loss: 280.3940 | Accuracy: 0.9226\n",
      "Epoch 24/25 | Loss: 254.3541 | Accuracy: 0.9313\n",
      "Epoch 25/25 | Loss: 235.8006 | Accuracy: 0.9370\n"
     ]
    }
   ],
   "source": [
    "num_epochs =25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for title_batch, text_batch, labels in train_loader:\n",
    "        title_batch = title_batch.to(device)\n",
    "        text_batch = text_batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(title_batch, text_batch)  \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Accuracy\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} | Loss: {epoch_loss:.4f} | Accuracy: {acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48766eb1-ec98-4506-b6fd-0d6adad2adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/lstm_word2vec.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bd77da3-a392-4192-9d5f-2ed5f3ab07df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for title_batch, text_batch, _ in test_loader:\n",
    "        title_batch = title_batch.to(device)\n",
    "        text_batch = text_batch.to(device)\n",
    "\n",
    "        outputs = model(title_batch, text_batch)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d4d20bd-e3c2-498f-94fd-1d304b7a54e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({\n",
    "    'label': test_labels,\n",
    "    'pred_w2v': all_preds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64061e4f-53ee-4731-9619-63e545a9070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results.to_csv('test_with_w2v.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cb5890-affd-40bb-a83a-4bbce4cb9ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
